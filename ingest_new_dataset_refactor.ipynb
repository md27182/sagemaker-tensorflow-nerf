{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "apparent-wrapping",
   "metadata": {},
   "source": [
    "### Set notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'sl2'\n",
    "dataset_id = '201030034508'\n",
    "\n",
    "dataset_path = '/home/ec2-user/SageMaker/lbx-nerf/data/' + dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-exhibition",
   "metadata": {},
   "source": [
    "### Download source images from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "s3uri = 's3://lbxlabs.scandata/' + dataset_id + '/'\n",
    "\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "!aws s3 cp $s3uri $dataset_path --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-charlotte",
   "metadata": {},
   "source": [
    "Make sure the dataset folder has the following subfolders:\n",
    "/home/ec2-user/SageMaker/lbx-nerf/data/{dataset_name} \n",
    "```\n",
    "├── images\n",
    "└── calibration_data  \n",
    "    ├── cam_dist_list.npy\n",
    "    ├── cam_extrinsics.npy \n",
    "    ├── cam_locations.npy \n",
    "    └── cam_mtx_list.npy \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-yellow",
   "metadata": {},
   "source": [
    "### Generate poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "intrinsics = np.load(dataset_path + '/calibration_data/cam_mtx_list.npy')\n",
    "extrinsics = np.load(dataset_path + '/calibration_data/cam_extrinsics.npy')\n",
    "locations = np.load(dataset_path + '/calibration_data/cam_locations.npy')\n",
    "print(f'Intrinsics have shape: {intrinsics.shape}')\n",
    "print(f'Extrinsics have shape: {extrinsics.shape}')\n",
    "print(f'Locations have shape: {locations.shape}')\n",
    "\n",
    "# Eventually, we can do everything in a vectorized way, but for now, to make things simple,\n",
    "# lets break apart each matrix\n",
    "intrinsics = [intr for intr in intrinsics]\n",
    "extrinsics = [ext for ext in extrinsics]\n",
    "locations = [loc for loc in locations]\n",
    "\n",
    "W = 6000\n",
    "H = 4000\n",
    "num_camera_columns = 120\n",
    "\n",
    "# Cosine and sine of 180 degrees\n",
    "c = -1 \n",
    "s = 0\n",
    "rot_x = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, c, -s, 0],\n",
    "    [0, s, c, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "bounds_w = 12 # Value is in cm, relative to camera-to-origin distance calculated below\n",
    "\n",
    "poses_bounds = []\n",
    "\n",
    "for index, (ext, loc) in enumerate(zip(extrinsics, locations)):\n",
    "    # Figure out which \"row\" this camera is in: we have to do this because the matrix of\n",
    "    # camera intrinsics has shape (27, 3, 3), while the other two arrays have shape (3240, ...) - \n",
    "    # this is because we only create one intrinsic matrix per \"row\" of the src cam locations\n",
    "    row = index // num_camera_columns\n",
    "    intr = intrinsics[row]\n",
    "    \n",
    "    # Apply an additional rotation of 180-degrees about the x-axis (OpenCV -> OpenGL convention)\n",
    "    #ext = np.matmul(ext, rot_x)\n",
    "    ext = np.matmul(rot_x, ext)\n",
    "\n",
    "    # Convert world-to-camera to camera-to-world\n",
    "    ext = np.linalg.inv(ext)\n",
    "    print_debug(f'Before \\n{ext}')\n",
    "    \n",
    "    # Get rid of the last row, which is always(0, 0, 0, 1)\n",
    "    ext = ext[:3, :]\n",
    "\n",
    "    # Flip the x and y columns\n",
    "    ext = ext[:, [1, 0, 2, 3]]\n",
    "\n",
    "    # Multiply the y column by -1\n",
    "    ext[:, 0] *= -1\n",
    "    print_debug(f'After \\n{ext}\\n')\n",
    "    \n",
    "    \n",
    "    # Append a 5th column to the matrix, which is [h, w, focal]\n",
    "    focal = (intr[0,0] + intr[1,1]) * 0.5\n",
    "    last_column = np.array([H, W, focal])\n",
    "    params = np.c_[ext, last_column]\n",
    "    print_debug(params)\n",
    "    \n",
    "\n",
    "    # Calculate the distance from the camera to the origin using the calibration data\n",
    "    distance_to_origin = np.linalg.norm(loc)\n",
    "    print_debug(f'Distance to origin: {distance_to_origin}')\n",
    "\n",
    "    # The \"near\" and \"far\" planes are just set to the distance calculated above +/- a fixed constant\n",
    "    near = distance_to_origin - bounds_w # np.min(distance_to_origin - bounds_w, loc[1]) # loc[1] is the height of the camera off the stage\n",
    "    far = 2.5 * distance_to_origin\n",
    "\n",
    "    # Flatten the 3x5 matrix into a 15-element row vector, append near and far bounds\n",
    "    params = params.reshape((15,))\n",
    "    params = np.append(params, [near, far])\n",
    "    print_debug(f'After reshaping: {params}')\n",
    "    \n",
    "    poses_bounds.append(params)\n",
    "\n",
    "poses_bounds = np.array(poses_bounds)\n",
    "print(f'All params shape: {poses_bounds.shape}')\n",
    "\n",
    "# Save .npy file\n",
    "np.save(dataset_path + '/poses_bounds.npy', poses_bounds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (nerf)",
   "language": "python",
   "name": "nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
